from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain_community.retrievers import WikipediaRetriever

# 1. LLM ì´ˆê¸°í™” (GPT-3.5-Turbo ê¸°ë³¸)
chat = ChatOpenAI(model="gpt-3.5-turbo")

# 2. Wikipedia ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì •
retriever = WikipediaRetriever(
    lang="ko",
    doc_content_chars_max=500,
    top_k_results=2
)

# 3. RetrievalQA ì²´ì¸ êµ¬ì„±
qa_chain = RetrievalQA.from_llm(
    llm=chat,
    retriever=retriever,
    return_source_documents=True
)

# 4. ì§ˆë¬¸ ì‹¤í–‰
query = "ì†Œì£¼ë€?"
result = qa_chain.invoke(query)  # âœ… ìµœì‹  ë°©ì‹: invoke

# 5. ê²°ê³¼ ë° ì¶œì²˜ ì¶œë ¥
source_documents = result["source_documents"]

print(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼: {len(source_documents)}ê±´")
for document in source_documents:
    print("---------------ê²€ìƒ‰í•œ ë©”íƒ€ë°ì´í„°---------------")
    print(document.metadata)
    print("---------------ê²€ìƒ‰í•œ í…ìŠ¤íŠ¸---------------")
    print(document.page_content[:100])

print("---------------ì‘ë‹µ---------------")
print(result["result"])
