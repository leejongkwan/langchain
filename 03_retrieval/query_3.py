from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain.chains import RetrievalQA
from langchain_core.documents import Document

# 1. LLM ë° ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
chat = ChatOpenAI(model="gpt-3.5-turbo")
embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")

# 2. Chroma ë¡œë“œ
vectorstore = Chroma(
    persist_directory="./.data",
    embedding_function=embeddings,
    collection_name="pdf_chunks"  # ì‚½ì… ì‹œ ì‚¬ìš©í•œ collection_nameê³¼ ì¼ì¹˜í•´ì•¼ í•¨
)

# 3. Retriever ë³€í™˜
retriever = vectorstore.as_retriever()

# 4. RetrievalQA ì²´ì¸ êµ¬ì„±
qa_chain = RetrievalQA.from_llm(
    llm=chat,
    retriever=retriever,
    return_source_documents=True
)

# 5. ì§ˆì˜ ì‹¤í–‰
query = "ë¹„í–‰ ìë™ì°¨ì˜ ìµœê³  ì†ë„ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”"
result = qa_chain.invoke(query)

# 6. ê²°ê³¼ ì¶œë ¥
print("ğŸ§  ë‹µë³€:")
print(result["result"])

print("\nğŸ“„ ì°¸ì¡° ë¬¸ì„œ:")
for doc in result["source_documents"]:
    print(f"- {doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
    print(doc.page_content[:300], "...\n")
