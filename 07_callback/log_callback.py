from langchain_core.callbacks import BaseCallbackHandler
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI


# ì»¤ìŠ¤í…€ ì½œë°± í•¸ë“¤ëŸ¬ ì •ì˜
class LogCallbackHandler(BaseCallbackHandler):
    def on_chat_model_start(self, serialized, messages, **kwargs):
        print("âœ… Chat model ì‹¤í–‰ ì‹œì‘...")
        print(f"ğŸ“¨ ì…ë ¥ ë©”ì‹œì§€: {messages}")

    def on_chain_start(self, serialized, inputs, **kwargs):
        print("ğŸ”— Chain ì‹¤í–‰ ì‹œì‘...")
        print(f"ğŸ“¥ ì…ë ¥: {inputs}")


# LLM ì´ˆê¸°í™” (ì½œë°± í•¸ë“¤ëŸ¬ í¬í•¨)
chat = ChatOpenAI(
    model="gpt-3.5-turbo",
    callbacks=[LogCallbackHandler()]
)

# LLM ì‹¤í–‰
result = chat.invoke([
    HumanMessage(content="ì•ˆë…•í•˜ì„¸ìš”!")
])

# ê²°ê³¼ ì¶œë ¥
print("ğŸ’¬ ì‘ë‹µ:", result.content)
